FROM debian:stretch

# required package installation(s)
RUN apt-get update
RUN apt-get -y install openssh-server ssh software-properties-common openjdk-8-jre wget dos2unix tar scala

# Setting up environment variables
ENV DAEMON_RUN=true
ENV SCALA_HOME=/usr/share/scala
ENV SPARK_HOME=/usr/local/spark
ENV SPARK_OPTS --driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info
ENV PYTHONPATH $SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.7-src.zip
ENV MASTER_CONTAINER_NAME=sparkmaster

# Get Apache Spark
RUN wget https://mirror.olnevhost.net/pub/apache/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz

# Install Spark and move it to the folder "/spark" and then add this location to the PATH env variable
RUN tar -xzf spark-3.0.1-bin-hadoop3.2.tgz && \
    mv spark-3.0.1-bin-hadoop3.2 /usr/local/spark && \
    rm spark-3.0.1-bin-hadoop3.2.tgz && \
    export PATH=$SPARK_HOME/bin:$PATH

# Inject Spark configurations
ADD /conf/env.sh /root/env.sh
RUN dos2unix /root/env.sh
RUN /root/env.sh
